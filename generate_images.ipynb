{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Copy of generate_images.ipynb","provenance":[{"file_id":"16ulUF-8mzJECbc5Nzi59qYM3aDhDm1YG","timestamp":1611774310443},{"file_id":"/piper/depot/tensorflow_gan/examples/colab_notebooks/tfgan_on_tpus.ipynb","timestamp":1606129140652},{"file_id":"/piper/depot/tensorflow_gan/examples/colab_notebooks/tfgan_on_tpus.ipynb","timestamp":1582841684055},{"file_id":"/piper/depot/tensorflow_gan/examples/colab_notebooks/tfgan_on_tpus.ipynb","timestamp":1569547310685},{"file_id":"/piper/depot/tensorflow_gan/examples/colab_notebooks/tfgan_on_tpus.ipynb","timestamp":1567688657181},{"file_id":"/piper/depot/tensorflow_gan/examples/colab_notebooks/tfgan_on_tpus.ipynb","timestamp":1564088453771},{"file_id":"/piper/depot/tensorflow_gan/examples/colab_notebooks/tfgan_on_tpus.ipynb","timestamp":1560586324901},{"file_id":"/piper/depot/tensorflow_gan/examples/colab_notebooks/tfgan_on_tpus.ipynb","timestamp":1559825146929},{"file_id":"/piper/depot/tensorflow_gan/examples/colab_notebooks/tfgan_on_tpus.ipynb","timestamp":1559658404997},{"file_id":"/piper/depot/tensorflow_gan/examples/colab_notebooks/tfgan_on_tpus.ipynb","timestamp":1559231931573},{"file_id":"0Bz8X96EaC_2-ZW9odlhSOEFXdWs","timestamp":1493398103910}],"collapsed_sections":[],"last_runtime":{"build_target":"//learning/brain/python/client:tpu_hw_notebook","kind":"private"}},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RB2DOo-xFoZ3"},"source":["# Generate Images\n","\n","Use TFGAN's GANEstimator to train a model on TPU to generate images of airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.\n","\n","Uses Deep Convolutional Generative Adversarial Network (DCGAN) architecture to adapt Convolutional Neural Networks (CNNs) for dealing with images."]},{"cell_type":"markdown","metadata":{"id":"u7A6mkRZGRqJ"},"source":["## TPU connection\n","\n","* Navigate to Edit → Notebook Settings → Hardware Accelerator = TPU\n","* Check that we can connect to the TPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjFF0NJMHXdm","executionInfo":{"elapsed":2182,"status":"ok","timestamp":1611773449218,"user":{"displayName":"likarajo","photoUrl":"https://lh3.googleusercontent.com/-Db9hrounrqg/AAAAAAAAAAI/AAAAAAAAkUw/GvMp5z1vaY4/s64/photo.jpg","userId":"12408627446919859441"},"user_tz":360},"outputId":"3a078ef6-33b6-4867-faa8-8ae693758a70"},"source":["import os\n","import tensorflow.compat.v1 as tf\n","import pprint\n","assert 'COLAB_TPU_ADDR' in os.environ, 'Did you forget to switch to TPU?'\n","tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","\n","with tf.Session(tpu_address) as sess:\n","  devices = sess.list_devices()\n","pprint.pprint(devices)\n","device_is_tpu = [True if 'TPU' in str(x) else False for x in devices]\n","assert True in device_is_tpu, 'Did you forget to switch to TPU?'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, -5438336312773099473),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3940608670928494938),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -1286911392309231460),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2780663737291636112),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2884526665050947995),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -970520913650829580),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 3277700708642474361),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -3585997035800732648),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6958148156217588824),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7256744659340994406),\n"," _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 1554863943405257720)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MeoJnwf8CT5J"},"source":["### Authentication\n","\n","* To run on Google's free Cloud TPUs, set up a [Google Cloud Storage bucket](https://cloud.google.com/storage/) to store logs and checkpoints. \n","* Running this notebook alone should fall under the [free pricing tier](https://cloud.google.com/storage/pricing)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"by1-zWuuCWsD","executionInfo":{"status":"ok","timestamp":1611774204168,"user_tz":360,"elapsed":1438,"user":{"displayName":"likarajo","photoUrl":"https://lh3.googleusercontent.com/-Db9hrounrqg/AAAAAAAAAAI/AAAAAAAAkUw/GvMp5z1vaY4/s64/photo.jpg","userId":"12408627446919859441"}},"outputId":"34ba792f-528d-462f-c23c-376411a41273"},"source":["import json\n","import os\n","import pprint\n","import re\n","import time\n","import tensorflow.compat.v1 as tf\n","import tensorflow_gcs_config\n","\n","# Storage bucket for Estimator logs and training dataset.\n","bucket = 'likarajo_bucket' #@param {type:\"string\"}\n","\n","assert bucket, 'Must specify an existing GCS bucket name'\n","print('Using bucket: {}'.format(bucket))\n","\n","model_dir = 'gs://{}/{}'.format(bucket, time.strftime('tpuestimator-tfgan/%Y-%m-%d-%H-%M-%S'))\n","print('Using model dir: {}'.format(model_dir))\n","\n","assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n","tpu_address = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","# Upload credentials to TPU.\n","tf.config.experimental_connect_to_host(tpu_address)\n","tensorflow_gcs_config.configure_gcs_from_colab_auth()\n","# Now credentials are set for all future sessions on this TPU."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using bucket: likarajo_bucket\n","Using model dir: gs://likarajo_bucket/tpuestimator-tfgan/2021-01-27-19-03-25\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[None, <tf.Tensor: shape=(), dtype=int32, numpy=0>]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"wiV9VpWKbnLN"},"source":["## Import necessary packages"]},{"cell_type":"code","metadata":{"id":"nXDNWK1BbpJm"},"source":["import os\n","\n","import tensorflow.compat.v1 as tf\n","# Disable noisy outputs.\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","tf.autograph.set_verbosity(0, False)\n","\n","try:\n","  import tensorflow_gan as tfgan\n","except ModuleNotFoundError:\n","  !pip install tensorflow-gan\n","  import tensorflow_gan as tfgan\n","\n","import tensorflow_datasets as tfds\n","\n","import tensorflow_hub as hub\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","# Allow matplotlib images to render immediately.\n","%matplotlib inline\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w7GkdNB6QB7b"},"source":["## Get Data\n","\n","[CIFAR10](https://wikipedia.org/wiki/CIFAR-10) dataset\n"]},{"cell_type":"markdown","metadata":{"id":"PoVOsRlPCDP8"},"source":["### Input pipeline\n"]},{"cell_type":"code","metadata":{"id":"3ADoVivQCGfA"},"source":["import tensorflow.compat.v1 as tf\n","import tensorflow_datasets as tfds\n","\n","dataset_dir = 'gs://{}/{}'.format(bucket, 'datasets')\n","\n","def input_fn(mode, params):\n","  assert 'batch_size' in params\n","  assert 'noise_dims' in params\n","  bs = params['batch_size']\n","  nd = params['noise_dims']\n","  split = 'train' if mode == tf.estimator.ModeKeys.TRAIN else 'test'\n","  shuffle = (mode == tf.estimator.ModeKeys.TRAIN)\n","  just_noise = (mode == tf.estimator.ModeKeys.PREDICT)\n","  \n","  noise_ds = (tf.data.Dataset.from_tensors(0)\n","              .map(lambda _: tf.random_normal([bs, nd]))\n","              # If 'predict', just generate one batch.\n","              .repeat(1 if just_noise else None))\n","  \n","  if just_noise:\n","    return noise_ds\n","\n","  def _preprocess(element):\n","    # Map [0, 255] to [-1, 1].\n","    images = (tf.cast(element['image'], tf.float32) - 127.5) / 127.5\n","    return images\n","\n","  images_ds = (tfds.load('cifar10:3.*.*', split=split, data_dir=dataset_dir)\n","               .map(_preprocess, num_parallel_calls=4)\n","               .cache()\n","               .repeat())\n","  if shuffle:\n","    images_ds = images_ds.shuffle(\n","        buffer_size=10000, reshuffle_each_iteration=True)\n","  images_ds = (images_ds.batch(bs, drop_remainder=True)\n","               .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","  return tf.data.Dataset.zip((noise_ds, images_ds))\n","\n","\n","def noise_input_fn(params):\n","  np.random.seed(0)\n","  np_noise = np.random.randn(params['batch_size'], params['noise_dims'])\n","  return tf.data.Dataset.from_tensors(tf.constant(np_noise, dtype=tf.float32))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yQLE0ya-N9bK"},"source":["### Download the data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361},"id":"Yyg-VjfRNJff","executionInfo":{"status":"error","timestamp":1611774220756,"user_tz":360,"elapsed":6753,"user":{"displayName":"likarajo","photoUrl":"https://lh3.googleusercontent.com/-Db9hrounrqg/AAAAAAAAAAI/AAAAAAAAkUw/GvMp5z1vaY4/s64/photo.jpg","userId":"12408627446919859441"}},"outputId":"9b03ed4d-d0a0-435c-b4d1-4aede6cb5760"},"source":["params = {'batch_size': 1, 'noise_dims':1}\n","input_fn(tf.estimator.ModeKeys.EVAL, params)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1mDownloading and preparing dataset cifar10/3.0.2 (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to gs://likarajo_bucket/datasets/cifar10/3.0.2...\u001b[0m\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-0e87204247b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'noise_dims'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-ec8f86310b3d>\u001b[0m in \u001b[0;36minput_fn\u001b[0;34m(mode, params)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   images_ds = (tfds.load('cifar10:3.*.*', split=split, data_dir=dataset_dir)\n\u001b[0m\u001b[1;32m     29\u001b[0m                \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                \u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    370\u001b[0m     dl_manager = self._make_download_manager(\n\u001b[1;32m    371\u001b[0m         \u001b[0mdownload_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         download_config=download_config)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;31m# Create a tmp dir and rename to self._data_dir on successful exit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_make_download_manager\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mforce_extraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFORCE_REDOWNLOAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mforce_checksums_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_checksums_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mregister_checksums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_checksums\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m     )\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, download_dir, extract_dir, manual_dir, manual_dir_instructions, url_infos, dataset_name, force_download, force_extraction, force_checksums_validation, register_checksums)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manual_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanual_dir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanual_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manual_dir_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanual_dir_instructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_download\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m   \"\"\"\n\u001b[0;32m--> 483\u001b[0;31m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 'object' must be a non-empty string. (File: gs://likarajo_bucket/)"]}]},{"cell_type":"markdown","metadata":{"id":"rW4SlJk0COjP"},"source":["### Sanity check the data\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378},"id":"X9vWFknACPvF","executionInfo":{"status":"error","timestamp":1611773865633,"user_tz":360,"elapsed":7799,"user":{"displayName":"likarajo","photoUrl":"https://lh3.googleusercontent.com/-Db9hrounrqg/AAAAAAAAAAI/AAAAAAAAkUw/GvMp5z1vaY4/s64/photo.jpg","userId":"12408627446919859441"}},"outputId":"ab415764-7734-4b3a-9e1a-ce05eccd32c6"},"source":["import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","import tensorflow_gan as tfgan\n","\n","params = {'batch_size': 80, 'noise_dims':64}\n","ds = input_fn(tf.estimator.ModeKeys.EVAL, params)\n","numpy_imgs = next(iter(tfds.as_numpy(ds)))[1]\n","image_grid = tfgan.eval.python_image_grid(numpy_imgs, grid_shape=(8, 10))\n","\n","def _show_image_grid(image_grid):\n","  plt.axis('off')\n","  plt.imshow((image_grid + 1.0) / 2.0,  # [-1, 1] -> [0, 1]\n","             aspect='auto')\n","  plt.show()\n","_show_image_grid(image_grid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1mDownloading and preparing dataset cifar10/3.0.2 (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to gs://likarajo_bucket/datasets/cifar10/3.0.2...\u001b[0m\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-65b7dac5fff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'noise_dims'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-ec8f86310b3d>\u001b[0m in \u001b[0;36minput_fn\u001b[0;34m(mode, params)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   images_ds = (tfds.load('cifar10:3.*.*', split=split, data_dir=dataset_dir)\n\u001b[0m\u001b[1;32m     29\u001b[0m                \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                \u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    370\u001b[0m     dl_manager = self._make_download_manager(\n\u001b[1;32m    371\u001b[0m         \u001b[0mdownload_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         download_config=download_config)\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;31m# Create a tmp dir and rename to self._data_dir on successful exit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_make_download_manager\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mforce_extraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFORCE_REDOWNLOAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mforce_checksums_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_checksums_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mregister_checksums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_checksums\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m     )\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, download_dir, extract_dir, manual_dir, manual_dir_instructions, url_infos, dataset_name, force_download, force_extraction, force_checksums_validation, register_checksums)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manual_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanual_dir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanual_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manual_dir_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanual_dir_instructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_download\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m   \"\"\"\n\u001b[0;32m--> 483\u001b[0;31m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 'object' must be a non-empty string. (File: gs://likarajo_bucket/)"]}]},{"cell_type":"markdown","metadata":{"id":"MfmvF-krJhQi"},"source":["## Neural Net Architecture\n","\n","GAN\n","*  A generator that takes input noise and outputs images\n","*  A discriminator that takes images and outputs a probability of being real"]},{"cell_type":"markdown","metadata":{"id":"3QuRrFtWFCUB"},"source":["### Network building functions"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"QV_qFuUwJcOb"},"source":["def _leaky_relu(x):\n","  return tf.nn.leaky_relu(x, alpha=0.2)\n","\n","\n","def _batch_norm(x, is_training, name):\n","  return tf.layers.batch_normalization(\n","      x, momentum=0.9, epsilon=1e-5, training=is_training, name=name)\n","\n","\n","def _dense(x, channels, name):\n","  return tf.layers.dense(\n","      x, channels,\n","      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","      name=name)\n","\n","\n","def _conv2d(x, filters, kernel_size, stride, name):\n","  return tf.layers.conv2d(\n","      x, filters, [kernel_size, kernel_size],\n","      strides=[stride, stride], padding='same',\n","      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","      name=name)\n","\n","\n","def _deconv2d(x, filters, kernel_size, stride, name):\n","  return tf.layers.conv2d_transpose(\n","      x, filters, [kernel_size, kernel_size],\n","      strides=[stride, stride], padding='same',\n","      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","      name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YX1F2V7bFO18"},"source":["### Discriminator"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Dp_3W4jgFQzH"},"source":["def discriminator(images, unused_conditioning, is_training=True,\n","                  scope='Discriminator'):\n","  \"\"\"Discriminator for CIFAR images.\n","\n","  Args:\n","    images: A Tensor of shape [batch size, width, height, channels], that can be\n","      either real or generated. It is the discriminator's goal to distinguish\n","      between the two.\n","    unused_conditioning: The TFGAN API can help with conditional GANs, which\n","      would require extra `condition` information to both the generator and the\n","      discriminator. Since this example is not conditional, we do not use this\n","      argument.\n","    is_training: If `True`, batch norm uses batch statistics. If `False`, batch\n","      norm uses the exponential moving average collected from population\n","      statistics.\n","    scope: A variable scope or string for the discriminator.\n","\n","  Returns:\n","    A 1D Tensor of shape [batch size] representing the confidence that the\n","    images are real. The output can lie in [-inf, inf], with positive values\n","    indicating high confidence that the images are real.\n","  \"\"\"\n","  with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n","    x = _conv2d(images, 64, 5, 2, name='d_conv1')\n","    x = _leaky_relu(x)\n","\n","    x = _conv2d(x, 128, 5, 2, name='d_conv2')\n","    x = _leaky_relu(_batch_norm(x, is_training, name='d_bn2'))\n","\n","    x = _conv2d(x, 256, 5, 2, name='d_conv3')\n","    x = _leaky_relu(_batch_norm(x, is_training, name='d_bn3'))\n","\n","    x = tf.reshape(x, [-1, 4 * 4 * 256])\n","\n","    x = _dense(x, 1, name='d_fc_4')\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m8qbS_fEFS5o"},"source":["### Generator"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"FvoBLhfrFV7x"},"source":["def generator(noise, is_training=True, scope='Generator'):\n","  \"\"\"Generator to produce CIFAR images.\n","\n","  Args:\n","    noise: A 2D Tensor of shape [batch size, noise dim]. Since this example\n","      does not use conditioning, this Tensor represents a noise vector of some\n","      kind that will be reshaped by the generator into CIFAR examples.\n","    is_training: If `True`, batch norm uses batch statistics. If `False`, batch\n","      norm uses the exponential moving average collected from population\n","      statistics.\n","    scope: A variable scope or string for the generator.\n","\n","  Returns:\n","    A single Tensor with a batch of generated CIFAR images.\n","  \"\"\"\n","  with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n","    net = _dense(noise, 4096, name='g_fc1')\n","    net = tf.nn.relu(_batch_norm(net, is_training, name='g_bn1'))\n","\n","    net = tf.reshape(net, [-1, 4, 4, 256])\n","\n","    net = _deconv2d(net, 128, 5, 2, name='g_dconv2')\n","    net = tf.nn.relu(_batch_norm(net, is_training, name='g_bn2'))\n","\n","    net = _deconv2d(net, 64, 4, 2, name='g_dconv3')\n","    net = tf.nn.relu(_batch_norm(net, is_training, name='g_bn3'))\n","\n","    net = _deconv2d(net, 3, 4, 2, name='g_dconv4')\n","    net = tf.tanh(net)\n","\n","    return net"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FGjCPvu7DnCT"},"source":["### Evaluation Utilities\n","\n","Metrics:\n","* `Inception Score`\n","* `Frechet Inception Distance`\n"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"spDJ_oEOELqS"},"source":["import tensorflow.compat.v1 as tf\n","import tensorflow_gan as tfgan\n","import tensorflow_hub as hub\n","import numpy as np\n","tf.disable_eager_execution()\n","\n","eval_batch_size = 4000 #@param\n","images_per_batch = 2000 #@param\n","\n","def get_real_image_logits(num_images, classifier_model):\n","  \"\"\"Returns an array with logits from real images and a CIFAR classifier.\n","  \n","  We normally want many thousands of examples to run eval. However, we can't fit\n","  inference for all of them in memory at once. Instead, we use TF-GAN eval utils\n","  to more efficiently manage memory.\n","\n","  Args:\n","    num_images: Total number of images to produce logits for.\n","    classifier_model: A Python function that takes images and produces logits.\n","\n","  Returns:\n","    A numpy array of logits of shape close to [num_images, ?].\n","  \"\"\"\n","  ds = input_fn(tf.estimator.ModeKeys.TRAIN, \n","                {'batch_size': images_per_batch, 'noise_dims': 1})\n","  iterator = tf.data.make_one_shot_iterator(ds)\n","\n","  cifar_imgs = iterator.get_next()[1]\n","  real_logits = classifier_model(cifar_imgs)\n","  \n","  with tf.train.MonitoredSession() as sess:\n","    logits = sess.run(real_logits)\n","  assert len(logits.shape) == 2\n","  assert logits.shape[0] == num_images\n","  return logits\n","\n","def init_global_real_logits():\n","  \"\"\"Initialize a global variable with classifier logits for real data.\"\"\"\n","  # We can hold all the real logits in memory at once, since CIFAR10 isn't that\n","  # big. Be sure to calculate it only once.\n","  global real_logits\n","  try:\n","    real_logits is not None\n","  except NameError:\n","    with tf.Graph().as_default():\n","      classifier_model = hub.Module(\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\")\n","      real_logits = get_real_image_logits(\n","          eval_batch_size, classifier_model)\n","  assert real_logits.shape == (eval_batch_size, 10)\n","  \n","def calculate_real_data_classifier_score():\n","  \"\"\"Calculate the classifier score on real data logits.\"\"\"\n","  assert real_logits is not None\n","  classifier_score = tfgan.eval.classifier_score_from_logits(real_logits)\n","  with tf.train.MonitoredSession() as sess:\n","    cscore_real = sess.run(classifier_score)\n","  return cscore_real\n","\n","\n","def get_inception_score_and_fid(est):\n","  \"\"\"Calculate our evaluation metrics.\"\"\"\n","  global real_logits\n","  assert real_logits is not None\n","\n","  tf.reset_default_graph()\n","  # We dont' want to hold all the images and activations at once, so use a\n","  # memory-efficient utility.\n","  def sample_fn():\n","    predictions = np.array([x['generated_data'] for x in est.predict(input_fn)])\n","    assert predictions.shape == (images_per_batch, 32, 32, 3)\n","    return predictions\n","  fake_imgs = tf.concat(\n","      [sample_fn() for _ in range(eval_batch_size // images_per_batch)], axis=0)\n","\n","  classifier_fn = hub.Module(\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\")\n","  fake_logits = classifier_fn(fake_imgs)\n","  fake_logits.shape.assert_is_compatible_with([eval_batch_size, 10])\n","\n","  classifier_score = tfgan.eval.classifier_score_from_logits(fake_logits)\n","  fid = tfgan.eval.frechet_classifier_distance_from_activations(\n","      real_logits, fake_logits)\n","\n","  with tf.train.MonitoredSession() as sess:\n","    cscore_np, fid_np = sess.run([classifier_score, fid])\n","  \n","  return cscore_np, fid_np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qqqK3sgWLQxi"},"source":["### GAN Estimator\n","\n","TF-GAN's `TPUGANEstimator` extends TensorFlow's `TPUEstimator` class. `TPUEstimator` handles the details of deploying the network on a TPU."]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"QDuTQjvBLSc2"},"source":["import os\n","import tensorflow.compat.v1 as tf\n","import tensorflow_gan as tfgan\n","tf.disable_eager_execution()\n","\n","noise_dims = 1024 #@param\n","generator_lr = 0.0002  #@param\n","discriminator_lr = 0.0002  #@param\n","train_batch_size = 1024  #@param\n","\n","config = tf.estimator.tpu.RunConfig(\n","    model_dir=model_dir,\n","    master=tpu_address,\n","    tpu_config=tf.estimator.tpu.TPUConfig(iterations_per_loop=images_per_batch))\n","est = tfgan.estimator.TPUGANEstimator(\n","    generator_fn=generator,\n","    discriminator_fn=discriminator,\n","    generator_loss_fn=tfgan.losses.modified_generator_loss,\n","    discriminator_loss_fn=tfgan.losses.modified_discriminator_loss,\n","    generator_optimizer=tf.train.AdamOptimizer(generator_lr, 0.5),\n","    discriminator_optimizer=tf.train.AdamOptimizer(discriminator_lr, 0.5),\n","    joint_train=True,  # train G and D jointly instead of sequentially.\n","    train_batch_size=train_batch_size,\n","    predict_batch_size=images_per_batch,\n","    use_tpu=True,\n","    params={'noise_dims': noise_dims},\n","    config=config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7juQranbJu_3"},"source":["## GAN Training and Evaluation"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"wcJ9dJqeJwwk"},"source":["import time\n","import matplotlib.pyplot as plt\n","\n","max_steps = 50000 #@param\n","steps_per_eval = 5000 #@param\n","\n","cur_step = 0\n","start_time = time.time()\n","cscores, fids, steps = [], [], []\n","init_global_real_logits()\n","print('Initialized classifier logits for real data.')\n","classifier_score_real_data = calculate_real_data_classifier_score()\n","print('Calculated classifier score for real data.')\n","while cur_step < max_steps:\n","  # Train for a fixed number of steps.\n","  start_step = cur_step\n","  step_to_stop_at = min(cur_step + steps_per_eval, max_steps)\n","  start = time.time()\n","  est.train(input_fn, max_steps=step_to_stop_at)\n","  end = time.time()\n","  cur_step = step_to_stop_at\n","  \n","  # Print some performance statistics.\n","  steps_taken = step_to_stop_at - start_step\n","  time_taken = end - start\n","  steps_per_sec = steps_taken / time_taken\n","  min_since_start = (time.time() - start_time) / 60.0\n","  print(\"Current step: %i, %.4f steps / sec, time since start: %.1f min\" % (\n","      cur_step, steps_per_sec, min_since_start))\n","  \n","  # Calculate some evaluation metrics.\n","  eval_start_time = time.time()\n","  cscore, fid = get_inception_score_and_fid(est)\n","  eval_time = (time.time() - eval_start_time)\n","  cscores.append(cscore)\n","  fids.append(fid)\n","  steps.append(cur_step)\n","  print(\"Classifier score: %.2f / %.2f, FID: %.1f, \"\n","        \"time to calculate eval: %.2f sec\" % (\n","            cscore, classifier_score_real_data, fid, eval_time))\n","  \n","  # Generate and show some predictions.\n","  predictions = np.array(\n","      [x['generated_data'] for x in est.predict(noise_input_fn)])[:80]\n","  image_grid = tfgan.eval.python_image_grid(predictions, grid_shape=(8, 10))\n","  _show_image_grid(image_grid)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"miWMXBi1GIVX"},"source":["### Metric Visualization"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"pTh96VyfEf7_"},"source":["# Plot the metrics vs step.\n","plt.title('Frechet distance per step')\n","plt.plot(steps, fids)\n","plt.figure()\n","plt.title('Classifier Score per step')\n","plt.plot(steps, cscores)\n","plt.plot(steps, [classifier_score_real_data] * len(steps))\n","plt.figure()"],"execution_count":null,"outputs":[]}]}